{
 "metadata": {
  "name": "",
  "signature": "sha256:b61637f408a54ba91d230fe3700243221781df431de1c1c39e74d10c7f2546e3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### previous code\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "## KMeans\n",
      "class KMeans:\n",
      "    def __init__(self, data, k):\n",
      "        self.data = data # data n x m\n",
      "        self.k = k # number of clusters k\n",
      "    \n",
      "    def _first_centroids(self):\n",
      "        # draw k randomly from range(0, the number of rows) in data\n",
      "        centroid_index = np.random.choice(range(self.data.shape[0]), self.k, replace=False)\n",
      "        return self.data[centroid_index,:]\n",
      "    \n",
      "    def _compare_centroids(self, old_centroids, new_centroids, P=-1):\n",
      "        if P == -1:\n",
      "            return np.array_equal(old_centroids,new_centroids)\n",
      "        else:\n",
      "            diff = np.sum((new_centroids - old_centroids)**2, axis=1)\n",
      "            if np.max(diff) <= P:\n",
      "                return True\n",
      "            else:\n",
      "                return False\n",
      "    \n",
      "    def _iterations(self):\n",
      "        centroids = self._first_centroids() # centroids k x m\n",
      "        \n",
      "        converged = False\n",
      "        cluster_values = []\n",
      "        interations = 0\n",
      "        \n",
      "        while (not converged) and (iterations < 1000):\n",
      "            print ('interation:', interations)\n",
      "            try: \n",
      "                \n",
      "                data_points = self.data[:, np.newaxis, :] \n",
      "                # data_points n x k x m\n",
      "                # data shape = n x m\n",
      "                # centroids shape = k x m\n",
      "                \n",
      "                ## calculate the Euclidean distance between a centroid and a data point\n",
      "                euclidean_dist = (data_points - centroids) ** 2\n",
      "                sum_up_dist = np.sum(euclidean_dist, axis=2) # total distance\n",
      "                \n",
      "                ## clustering, which cluster each data point belongs\n",
      "                min_dist = np.zeros(sum_up_dist.shape)\n",
      "                min_dist[range(sum_up_dist.shape[0]), np.argmin(sum_up_dist, axis=1)] = 1\n",
      "                # [i,j] = 1 in matrix (n x k) if the ith data point belongs to cluster j\n",
      "                \n",
      "                ## clusters\n",
      "                cluster_val = np.sum(sum_up_dist[min_dist == True])\n",
      "                cluster_values.append(cluster_val)\n",
      "                \n",
      "                # new centroids\n",
      "                new_centroids = np.empty(centroids.shape)\n",
      "                for i in range(0, self.k):\n",
      "                    if self.data[min_dist[:,i] == True,:].shape[0] == 0:\n",
      "                        new_centroids[i] = centroids[i]\n",
      "                    else:\n",
      "                        new_centroids[i] = np.mean(self.data[min_dist[:,i] == True, :], axis=0)\n",
      "                \n",
      "                # comparing centroids\n",
      "                if self._compare_centroids(centroids, new_centroids):\n",
      "                    converged = True\n",
      "                else:\n",
      "                    centroids = new_centroids\n",
      "            except:\n",
      "                print ('exception!')\n",
      "                continue\n",
      "        \n",
      "        else:\n",
      "            iteration += 1\n",
      "        print ('Required', iterations, 'interations to converge.')\n",
      "        return iterations, cluster_values, centroids, min_dist\n",
      "    \n",
      "    def clustering(self):\n",
      "        return self._iterations()\n",
      "\n",
      "    import numpy as np\n",
      "    \n",
      "## KMeansPlusPlus\n",
      "class KMeansPlusPlus(KMeans):\n",
      "    def __init__(self, data, k):\n",
      "        KMeans.__init__(self, data, k)\n",
      "    \n",
      "    def _first_centroids(self):\n",
      "        centroids = self.data[np.random.choice(range(self.data.shape[0]),1), :]\n",
      "        data_points = self.data[:, np.newaxis, :]\n",
      "        \n",
      "        # run k-1 passes\n",
      "        while centroids.shape[0] < self.k :\n",
      "            euclidean_dist = (data_points - centroids) ** 2\n",
      "            sum_up_dist = np.sum(euclidean_dist, axis=2)\n",
      "            min_dist = np.zeros(sum_up_dist.shape)\n",
      "            min_dist[range(sum_up_dist.shape[0]), np.argmin(sum_up_dist, axis=1)] = 1\n",
      "            cluster_val = np.sum(sum_up_dist[min_dist == True])\n",
      "            \n",
      "            # probability distribution\n",
      "            prob_distribution = np.min(sum_up_dist, axis=1)/cluster_val\n",
      "\n",
      "            # choose the next centroid by using prob_distribution\n",
      "            centroids = np.vstack([centroids, self.data[np.random.choice(range(self.data.shape[0]),1,p=prob_distribution), :]])\n",
      "        return centroids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Algorithm 3. Scalable KMeansPlusPlus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "class ScalableKMeansPlusPlus(KMeans):\n",
      "    def __init__(self, data, k, l, i):\n",
      "        KMeans.__init__(self, data, k)\n",
      "        self.l = l\n",
      "        self.i = i\n",
      "        \n",
      "    def _first_centroids(self):\n",
      "        centroids = self.data[np.random.choice(range(self.data.shape[0]),1), :]\n",
      "        data_points = self.data[:, np.newaxis, :]\n",
      "        \n",
      "        passes = 0\n",
      "        while passes < self.i:\n",
      "            euclidean_dist = (data_points - centroids) ** 2\n",
      "            sum_up_dist = np.sum(euclidean_dist, axis=2)\n",
      "            # the weight = the minimum distance\n",
      "            weight = np.min(sum_up_dist, axis=1).reshape(-1,1)\n",
      "            # change zeros in weight with the lowest positive float\n",
      "            weight[np.where(weight==0)] = np.nextafter(0,1)\n",
      "            # make the same size of random number matrix with weight\n",
      "            # and (weight)th root of the matrix\n",
      "            random_matrix = np.random.rand(weight.shape[0],weight.shape[1])\n",
      "            with np.errstate(all='ignore'):\n",
      "                random_matrix = random_matrix ** (1.0/weight)\n",
      "            # choose the highest c\n",
      "            center = self.data[np.argsort(random_matrix, axis=0)[:, 0]][::-1][:self.l, :]\n",
      "            # combine the new centroids with the old one\n",
      "            centroids = np.vstack((centroids, center))\n",
      "            passes += 1\n",
      "            \n",
      "        # reduce the old centroids to k using KMeansPlusPlus\n",
      "        euclidean_dist = (data_points - centroids) ** 2\n",
      "        sum_up_dist = np.sum(euclidean_dist, axis=2)\n",
      "        min_dist = np.zeros(sum_up_dist.shape)\n",
      "        min_dist[range(sum_up_dist.shape[0]), np.argmin(sum_up_dist, axis=1)] = 1\n",
      "        weights = np.array([np.count_nonzero(min_dist[:, i]) for i in range(centroids.shape[0])]).reshape(-1,1)\n",
      "        #\n",
      "        KMeansPlusPlus = KMeansPlusPlus(weights, self.l)\n",
      "        _, _, _, min_dist = KMeansPlusPlus.cluster()\n",
      "        #\n",
      "        centroids_new = np.empty((self.l, self.data.shape[1]))\n",
      "        for i in range(0, self.l):\n",
      "            centroids_new[i] = np.mean(centroids[min_dist[:, i] == True, :], axis=0)\n",
      "        return centroids_new\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}